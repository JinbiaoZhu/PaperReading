# PaperReading

<div align=center>
  <image src="https://github.com/JinbiaoZhu/PaperReading/blob/main/pic/4301b348e0c44c7f96d6d7fb3d1e7730.gif?raw=true">
</div>

This is a Github repository that focuses on articles related to skill-based meta reinforcement learning. The main focus is on skill extraction, combination, and generalization.

 1. ğŸ˜Š[2023.07.05]ğŸ˜Š  Nam, Taewook, et al. "Skill-based meta-reinforcement learning." arXiv preprint arXiv:2204.11828 (2022).
 2. ğŸ˜Š[2023.07.11]ğŸ˜Š  Yoo, Minjong, Sangwoo Cho, and Honguk Woo. "Skills Regularized Task Decomposition for Multi-task Offline Reinforcement Learning." Advances in Neural Information Processing Systems 35 (2022): 37432-37444.
 3. ğŸ˜Š[2023.07.12]ğŸ˜Š  Cheng, Shuo, and Danfei Xu. "Guided Skill Learning and Abstraction for Long-Horizon Manipulation." arXiv preprint arXiv:2210.12631 (2022).
 4. ğŸ˜Š[2023.07.14]ğŸ˜Š  Guan, Lin, et al. "Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning." arXiv preprint arXiv:2305.14909 (2023).
 5. ğŸ˜Š[2023.07.16]ğŸ˜Š  Chen, Yongchao, et al. "AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers." arXiv preprint arXiv:2306.06531 (2023).
 6. ğŸ˜Š[2023.07.21]ğŸ˜Š  Myself. "RL-and-Variational-Inference-v2.pdf"
 7. ğŸ˜Š[2023.07.26]ğŸ˜Š  Myself. "SAC_logprob.md"

---

 1. ğŸ¥°[2023.08.16]ğŸ¥°  Huang, Wenlong, et al. "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents." International Conference on Machine Learning. PMLR, 2022.
 2. ğŸ¥°[2023.08.17]ğŸ¥°  Ding, Yan, et al. "Task and motion planning with large language models for object rearrangement." arXiv preprint arXiv:2303.06247 (2023).
 3. ğŸ¥°[2023.08.17]ğŸ¥°  Cao, Yue, and C. S. Lee. "Ground Manipulator Primitive Tasks to Executable Actions using Large Language Models." arXiv preprint arXiv:2308.06810 (2023).
 4. ğŸ¥°[2023.08.18]ğŸ¥°  Ding, Yan, et al. "Robot task planning and situation handling in open worlds." arXiv preprint arXiv:2210.01287 (2022).
 5. ğŸ¥°[2023.08.18]ğŸ¥°  Perez, Julien, et al. "LARG, Language-based Automatic Reward and Goal Generation." arXiv preprint arXiv:2306.10985 (2023).
 6. ğŸ¥°[2023.08.18]ğŸ¥°  Colas, CÃ©dric, et al. "Language-conditioned goal generation: a new approach to language grounding for RL." arXiv preprint arXiv:2006.07043 (2020).
 7. ğŸ¥°[2023.08.21]ğŸ¥°  Eysenbach, Benjamin, et al. "Diversity is all you need: Learning skills without a reward function." arXiv preprint arXiv:1802.06070 (2018).

---

 1. ğŸ˜˜[2023.09.25]ğŸ˜˜ Vemprala, Sai, et al. "Chatgpt for robotics: Design principles and model abilities." Microsoft Auton. Syst. Robot. Res 2 (2023): 20.
 2. ğŸ˜˜[2023.09.26]ğŸ˜˜ Liu, Haokun, et al. "LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks." arXiv preprint arXiv:2308.14972 (2023).

---

 1. ğŸ¤—[2023.10.02]ğŸ¤— Elhafsi, A., Sinha, R., Agia, C., Schmerling, E., Nesnas, I., and Pavone, M., â€œSemantic Anomaly Detection with Large Language Modelsâ€, <i>arXiv e-prints</i>, 2023. doi:10.48550/arXiv.2305.11307.
 2. ğŸ¤—[2023.10.06]ğŸ¤— Liang, J., â€œCode as Policies: Language Model Programs for Embodied Controlâ€, <i>arXiv e-prints</i>, 2022. doi:10.48550/arXiv.2209.07753.
 3. ğŸ¤—[2023.10.09]ğŸ¤— Jin, E., â€œMini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon Decision-Making in Embodied AIâ€, <i>arXiv e-prints</i>, 2023. doi:10.48550/arXiv.2310.01824.

