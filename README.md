# PaperReading

<div align=center>
  <image src="https://github.com/JinbiaoZhu/PaperReading/blob/main/pic/4301b348e0c44c7f96d6d7fb3d1e7730.gif?raw=true">
</div>

This is a Github repository that focuses on articles related to skill-based meta reinforcement learning. The main focus is on skill extraction, combination, and generalization.

 1. ðŸ˜Š[2023.07.05]ðŸ˜Š  Nam, Taewook, et al. "Skill-based meta-reinforcement learning." arXiv preprint arXiv:2204.11828 (2022).
 2. ðŸ˜Š[2023.07.11]ðŸ˜Š  Yoo, Minjong, Sangwoo Cho, and Honguk Woo. "Skills Regularized Task Decomposition for Multi-task Offline Reinforcement Learning." Advances in Neural Information Processing Systems 35 (2022): 37432-37444.
 3. ðŸ˜Š[2023.07.12]ðŸ˜Š  Cheng, Shuo, and Danfei Xu. "Guided Skill Learning and Abstraction for Long-Horizon Manipulation." arXiv preprint arXiv:2210.12631 (2022).
 4. ðŸ˜Š[2023.07.14]ðŸ˜Š  Guan, Lin, et al. "Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning." arXiv preprint arXiv:2305.14909 (2023).
 5. ðŸ˜Š[2023.07.16]ðŸ˜Š  Chen, Yongchao, et al. "AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers." arXiv preprint arXiv:2306.06531 (2023).
 6. ðŸ˜Š[2023.07.21]ðŸ˜Š  Myself. "RL-and-Variational-Inference-v2.pdf"
 7. ðŸ˜Š[2023.07.26]ðŸ˜Š  Myself. "SAC_logprob.md"

---

 1. ðŸ¥°[2023.08.16]ðŸ¥°  Huang, Wenlong, et al. "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents." International Conference on Machine Learning. PMLR, 2022.
 2. ðŸ¥°[2023.08.17]ðŸ¥°  Ding, Yan, et al. "Task and motion planning with large language models for object rearrangement." arXiv preprint arXiv:2303.06247 (2023).
 3. ðŸ¥°[2023.08.17]ðŸ¥°  Cao, Yue, and C. S. Lee. "Ground Manipulator Primitive Tasks to Executable Actions using Large Language Models." arXiv preprint arXiv:2308.06810 (2023).
 4. ðŸ¥°[2023.08.18]ðŸ¥°  Ding, Yan, et al. "Robot task planning and situation handling in open worlds." arXiv preprint arXiv:2210.01287 (2022).
 5. ðŸ¥°[2023.08.18]ðŸ¥°  Perez, Julien, et al. "LARG, Language-based Automatic Reward and Goal Generation." arXiv preprint arXiv:2306.10985 (2023).
 6. ðŸ¥°[2023.08.18]ðŸ¥°  Colas, CÃ©dric, et al. "Language-conditioned goal generation: a new approach to language grounding for RL." arXiv preprint arXiv:2006.07043 (2020).
 7. ðŸ¥°[2023.08.21]ðŸ¥°  Eysenbach, Benjamin, et al. "Diversity is all you need: Learning skills without a reward function." arXiv preprint arXiv:1802.06070 (2018).
